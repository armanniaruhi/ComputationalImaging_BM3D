{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import .exr file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T12:00:30.662227Z",
     "start_time": "2025-01-19T12:00:24.801893Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import bm3d\n",
    "from bm3d import bm3d, BM3DStages\n",
    "import bm3d.profiles as profiles\n",
    "import OpenEXR\n",
    "import Imath\n",
    "import math\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T12:00:30.677187Z",
     "start_time": "2025-01-19T12:00:30.671204Z"
    }
   },
   "outputs": [],
   "source": [
    "base_dir = os.getcwd()  # Current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T12:00:30.708105Z",
     "start_time": "2025-01-19T12:00:30.697135Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_exr(file_path):\n",
    "    \"\"\"\n",
    "    Processes an EXR file by loading its data, adjusting exposure and gamma,\n",
    "    and optionally displaying the original and adjusted images.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the EXR file.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (noisy_img, noisy_img_adjusted), where:\n",
    "               - noisy_img is the original HDR image as a NumPy array.\n",
    "               - noisy_img_adjusted is the adjusted image.\n",
    "    \"\"\"\n",
    "    # Open the EXR file\n",
    "    exr_file = OpenEXR.InputFile(file_path)\n",
    "\n",
    "    # Get the header and dimensions\n",
    "    header = exr_file.header()\n",
    "    dw = header['dataWindow']\n",
    "    width = dw.max.x - dw.min.x + 1\n",
    "    height = dw.max.y - dw.min.y + 1\n",
    "\n",
    "    # Channels to extract\n",
    "    channels = ['R', 'G', 'B']\n",
    "\n",
    "    # Determine pixel type\n",
    "    pixel_type = Imath.PixelType(Imath.PixelType.HALF)\n",
    "\n",
    "    # Allocate memory and load channels\n",
    "    img = np.empty((height, width, len(channels)), dtype=np.float16)\n",
    "    for i, channel in enumerate(channels):\n",
    "        raw_data = exr_file.channel(channel, pixel_type)\n",
    "        img[:, :, i] = np.frombuffer(raw_data, dtype=np.float16).reshape(height, width)\n",
    "\n",
    "    # Convert to float32 for processing\n",
    "    noisy_img = img.astype(np.float32)\n",
    "\n",
    "    return noisy_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T12:00:31.577781Z",
     "start_time": "2025-01-19T12:00:31.567807Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_snr(image_3channel):\n",
    "    \"\"\"Calculate SNR (Signal-to-Noise Ratio) in decibels using mean and max-min methods.\"\"\"\n",
    "    # Initialize lists for SNR per channel\n",
    "    snr_mean_per_channel = []\n",
    "    snr_max_min_per_channel = []\n",
    "\n",
    "    for channel in range(image_3channel.shape[2]):\n",
    "        channel_data = image_3channel[:, :, channel]\n",
    "        \n",
    "        # Signal using max-min\n",
    "        signal_max_min = channel_data.max() - channel_data.min()\n",
    "        \n",
    "        # Signal using mean\n",
    "        signal_mean = np.mean(channel_data)\n",
    "        \n",
    "        # Noise (Standard deviation)\n",
    "        noise = np.std(channel_data)\n",
    "        \n",
    "        # SNR using max-min and mean methods\n",
    "        snr_max_min = signal_max_min / noise\n",
    "        snr_mean = signal_mean / noise\n",
    "        \n",
    "        # Append to respective lists\n",
    "        snr_max_min_per_channel.append(snr_max_min)\n",
    "        snr_mean_per_channel.append(snr_mean)\n",
    "\n",
    "    # Compute overall SNR for max-min and mean methods\n",
    "    overall_snr_max_min = np.mean(snr_max_min_per_channel)\n",
    "    overall_snr_mean = np.mean(snr_mean_per_channel)\n",
    "\n",
    "    # Convert to decibels\n",
    "    snr_max_min_db = 20 * math.log(overall_snr_max_min, 10)\n",
    "    snr_mean_db = 20 * math.log(overall_snr_mean, 10)\n",
    "\n",
    "    return snr_max_min_db, snr_mean_db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T12:00:35.349206Z",
     "start_time": "2025-01-19T12:00:35.337239Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the NumPy array to a PyTorch tensor\n",
    "def numpy_to_torch(img_np):\n",
    "    # Ensure the dimensions are in the format [Channels, Height, Width]\n",
    "    if len(img_np.shape) == 2:  # Grayscale image\n",
    "        img_tensor = torch.tensor(img_np, dtype=torch.float32).unsqueeze(0)  # Add channel dimension\n",
    "    else:  # Color image\n",
    "        img_tensor = torch.tensor(img_np, dtype=torch.float32).permute(2, 0, 1).to(device)  # Rearrange dimensions\n",
    "\n",
    "    # Normalize the tensor values to [0, 1] (optional, depending on your use case)\n",
    "    img_tensor = torch.clamp(img_tensor, min=0)\n",
    "    img_tensor /= 255.0\n",
    "    img_tensor = img_tensor.unsqueeze(0)\n",
    "    img_tensor.requires_grad = True\n",
    "    \n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries for No Reference Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T12:00:40.436682Z",
     "start_time": "2025-01-19T12:00:39.285760Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install lpips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T12:00:41.767585Z",
     "start_time": "2025-01-19T12:00:40.440672Z"
    }
   },
   "outputs": [],
   "source": [
    "from piq import BRISQUELoss, TVLoss, CLIPIQA\n",
    "import lpips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T17:04:51.609390Z",
     "start_time": "2025-01-18T17:04:51.597396Z"
    }
   },
   "outputs": [],
   "source": [
    "from contextlib import redirect_stdout\n",
    "\n",
    "def load_lpips_model():\n",
    "    with open(os.devnull, \"w\") as f, redirect_stdout(f):\n",
    "        model = lpips.LPIPS(net='vgg').to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T12:00:43.456038Z",
     "start_time": "2025-01-19T12:00:43.384231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "CUDA Device Name: NVIDIA GeForce RTX 2070 SUPER\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Choose GPU or CPU\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"CUDA Device Name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T12:00:45.430454Z",
     "start_time": "2025-01-19T12:00:45.401505Z"
    }
   },
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "def process_bm3d(\n",
    "    type,\n",
    "    transform_2d_ht_names=[\"dct\", \"bior1.5\"],\n",
    "    max_3d_size_hts=[32],\n",
    "    max_3d_size_wieners=[32],\n",
    "    bs_wieners=[8],\n",
    "    step_wieners=[3],\n",
    "    bs_hts=[8],\n",
    "    nfs=[32],\n",
    "    search_window_hts=[39],\n",
    "    search_window_wieners=[39],\n",
    "    step_hts=[3],\n",
    "    tau_matchs=[3000],\n",
    "    tau_match_wieners=[400],\n",
    "    lambda_thr3ds=[2.7],\n",
    "    gammas=[2.0],\n",
    "    beta_wieners=[2.0]\n",
    "):\n",
    "\n",
    "    # Storage for results\n",
    "    results_data = []\n",
    "    index = 0\n",
    "    y_s = [15, 16, 17, 18, 19, 20, 21, 22]\n",
    "\n",
    "    # Combine parameters for grid search\n",
    "    parameter_combinations = itertools.product(\n",
    "        y_s,\n",
    "        transform_2d_ht_names,\n",
    "        max_3d_size_hts,\n",
    "        max_3d_size_wieners,\n",
    "        bs_wieners,\n",
    "        step_wieners,\n",
    "        bs_hts,\n",
    "        nfs,\n",
    "        search_window_hts,\n",
    "        search_window_wieners,\n",
    "        step_hts,\n",
    "        tau_matchs,\n",
    "        tau_match_wieners,\n",
    "        lambda_thr3ds,\n",
    "        gammas,\n",
    "        beta_wieners,\n",
    "    )\n",
    "\n",
    "    parameter_combinations = list(parameter_combinations)\n",
    "    total_combinations = len(parameter_combinations)\n",
    "\n",
    "    sigma_psd_values = [*range(5, 31, 5)]\n",
    "    stage_args = [BM3DStages.ALL_STAGES]\n",
    "    total_iterations = len(parameter_combinations) * len(stage_args) * len(sigma_psd_values)\n",
    "\n",
    "\n",
    "    with tqdm(range(total_iterations), desc=\"Progress\") as pbar:\n",
    "\n",
    "        # Iterate through all combinations\n",
    "        for i, params in enumerate(parameter_combinations):\n",
    "            (\n",
    "                y,\n",
    "                transform_2d_ht_name,\n",
    "                max_3d_size_ht,\n",
    "                max_3d_size_wiener,\n",
    "                bs_wiener,\n",
    "                step_wiener,\n",
    "                bs_ht,\n",
    "                nf,\n",
    "                search_window_ht,\n",
    "                search_window_wiener,\n",
    "                step_ht,\n",
    "                tau_match,\n",
    "                tau_match_wiener,\n",
    "                lambda_thr3d,\n",
    "                gamma,\n",
    "                beta_wiener,\n",
    "            ) = params\n",
    "\n",
    "            # Configure BM3D profile\n",
    "            profile = profiles.BM3DProfile()\n",
    "            # Transforms used\n",
    "            profile.transform_2d_ht_name = transform_2d_ht_name  # 'bior1.5'\n",
    "            profile.transform_2d_wiener_name = \"dct\"\n",
    "\n",
    "            # -- Exact variances for correlated noise: --\n",
    "\n",
    "            # Variance calculation parameters\n",
    "            profile.nf = nf  # 32  # domain size for FFT computations\n",
    "            profile.k = 4  # how many layers of var3D to calculate\n",
    "\n",
    "            # Block matching\n",
    "            profile.gamma = gamma  # 3.0  # Block matching correction factor\n",
    "\n",
    "            # -- Classic BM3D for correlated noise --\n",
    "\n",
    "            # Hard-thresholding (HT) parameters:\n",
    "            profile.bs_ht = bs_ht  # 8  # N1 x N1 is the block size used for the hard-thresholding (HT) filtering\n",
    "            profile.step_ht = (\n",
    "                step_ht  # 3# sliding step to process every next reference block\n",
    "            )\n",
    "            profile.max_3d_size_ht = max_3d_size_ht  # 16  # maximum number of similar blocks (maximum size of the 3rd dimension of a 3D array)\n",
    "            profile.search_window_ht = search_window_ht  # 39  # side length of the search neighborhood for full-search block-matching (BM), must be odd\n",
    "            profile.tau_match = (\n",
    "                tau_match  # 3000  # threshold for the block-distance (d-distance)\n",
    "            )\n",
    "\n",
    "            # None in these parameters results in automatic parameter selection for them\n",
    "            profile.lambda_thr3d = lambda_thr3d  # None  # 2.7  # threshold parameter for the hard-thresholding in 3D transform domain\n",
    "            profile.mu2 = lambda_thr3d  # None  # 1.0\n",
    "\n",
    "            # Wiener filtering parameters:\n",
    "            profile.bs_wiener = bs_wiener  # 8\n",
    "            profile.step_wiener = step_wiener  # 3\n",
    "            profile.max_3d_size_wiener = max_3d_size_wiener  # 32\n",
    "            profile.search_window_wiener = search_window_wiener  # 39\n",
    "            profile.tau_match_wiener = tau_match_wiener  # 400\n",
    "            profile.beta_wiener = beta_wiener  # 2.0\n",
    "            profile.dec_level = (\n",
    "                0  # dec. levels of the dyadic wavelet 2D transform for blocks\n",
    "            )\n",
    "\n",
    "            output_base_folder = f\"{base_dir}/Results/Leech results/{type}/\"\n",
    "            os.makedirs(output_base_folder, exist_ok=True)\n",
    "\n",
    "            file_path = f\"{base_dir}/Dataset/leech/2024_04_25_11_54_01_img_x_15_y_{y}_r_0_g_1_b_0_cropped.exr\"\n",
    "\n",
    "            # Load and preprocess noisy image\n",
    "            noisy_img = process_exr(file_path)  # 800x800\n",
    "            noisy_img = (noisy_img[:-10, :-10] * 255).astype(\"uint8\")\n",
    "\n",
    "            # Process each stage and sigma_psd value\n",
    "            for stage_arg in stage_args:\n",
    "                for sigma_psd in sigma_psd_values:\n",
    "                    # start timer\n",
    "                    start_time = time.time()\n",
    "\n",
    "                    denoised_img = bm3d(\n",
    "                        noisy_img, sigma_psd=sigma_psd, stage_arg=stage_arg, profile=profile\n",
    "                    )\n",
    "\n",
    "                    end_time = time.time()\n",
    "\n",
    "                    snr_max_min_db, snr_mean_db = calculate_snr(denoised_img)\n",
    "                    img_tensor = numpy_to_torch(denoised_img)\n",
    "\n",
    "                    # BRISQUELoss\n",
    "                    try:\n",
    "                        loss = BRISQUELoss(reduction=\"sum\").to(device)\n",
    "                        brsique_score = loss(img_tensor)\n",
    "                        brsique_score.backward()\n",
    "                        brsique_score = brsique_score.item()\n",
    "                    except:\n",
    "                        brsique_score = None\n",
    "\n",
    "                    # TV\n",
    "                    loss = TVLoss().to(device)\n",
    "                    tv = loss(img_tensor)\n",
    "                    tv.backward()\n",
    "                    tv = tv.item()\n",
    "\n",
    "                    # CLIP IQA\n",
    "                    try:\n",
    "                        clipiqa = CLIPIQA().to(device)\n",
    "                        clipiqa_score = clipiqa(img_tensor).item()#\n",
    "                    except:\n",
    "                        clipiqa_score = None\n",
    "\n",
    "\n",
    "                    # LPIPS\n",
    "                    try:\n",
    "                        noisy_img_torch = numpy_to_torch(noisy_img)\n",
    "                        loss_fn = load_lpips_model()\n",
    "                        lpips_score = loss_fn(noisy_img_torch, img_tensor).item()\n",
    "                    except:\n",
    "                        lpips_score = None\n",
    "\n",
    "                    denoised_img_float32 = (\n",
    "                        denoised_img.astype(\"float32\") / 255.0\n",
    "                    )  # Normalize to [0, 1] range\n",
    "                    # OpenEXR requires the data to be split into channels (R, G, B)\n",
    "                    R = denoised_img_float32[:, :, 0].tobytes()  # Red channel\n",
    "                    G = denoised_img_float32[:, :, 1].tobytes()  # Green channel\n",
    "                    B = denoised_img_float32[:, :, 2].tobytes()  # Blue channel\n",
    "\n",
    "                    # Define EXR header\n",
    "                    header = OpenEXR.Header(\n",
    "                        denoised_img_float32.shape[1], denoised_img_float32.shape[0]\n",
    "                    )  # Width, Height\n",
    "\n",
    "                    # Write the data to an EXR file\n",
    "                    path_final = output_base_folder + f\"{type}-{index}_image_res.exr\"\n",
    "                    exr_file = OpenEXR.OutputFile(path_final, header)\n",
    "                    exr_file.writePixels({\"R\": R, \"G\": G, \"B\": B})\n",
    "                    exr_file.close()\n",
    "\n",
    "                    # Store all parameter values and results\n",
    "                    results_data.append(\n",
    "                        {\n",
    "                            \"Coordinate y\": y,\n",
    "                            \"Sigma PSD\": sigma_psd,\n",
    "                            \"Stage_arg\": stage_arg,\n",
    "                            \"Transform 2D\": transform_2d_ht_name,\n",
    "                            \"Max 3D Size HT\": max_3d_size_ht,\n",
    "                            \"Max 3D Size Wiener\": max_3d_size_wiener,\n",
    "                            \"Block Size Wiener\": bs_wiener,\n",
    "                            \"Step Wiener\": step_wiener,\n",
    "                            \"Block Size HT\": bs_ht,\n",
    "                            \"Step HT\": step_ht,\n",
    "                            \"Number of Features (NF)\": nf,\n",
    "                            \"Search Window HT\": search_window_ht,\n",
    "                            \"Search Window Wiener\": search_window_wiener,\n",
    "                            \"Tau Match\": tau_match,\n",
    "                            \"Tau Match Wiener\": tau_match_wiener,\n",
    "                            \"Lambda Thr3D\": lambda_thr3d,\n",
    "                            \"Gamma\": gamma,\n",
    "                            \"Beta Wiener\": beta_wiener,\n",
    "                            \"SNR Max-Min (dB)\": snr_max_min_db,\n",
    "                            \"SNR Mean (dB)\": snr_mean_db,\n",
    "                            \"BRISQUE\": brsique_score,\n",
    "                            \"Total Variation\": tv,\n",
    "                            \"Clip-IQA\": clipiqa_score,\n",
    "                            \"LPIPs_score\" : lpips_score,\n",
    "                            \"Computation Time\" : end_time,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "                    # Convert to a DataFrame\n",
    "                    pbar.set_postfix(Index = index, y = y, SNR = snr_max_min_db, BRISQUE = brsique_score, TV_loss = tv, Clip_IQA = clipiqa_score, LPIPs_score = lpips_score, Computation_Time = end_time)\n",
    "                    pbar.update(1)\n",
    "\n",
    "                    df = pd.DataFrame(results_data)\n",
    "                    # Save to Excel\n",
    "                    df.to_excel(\n",
    "                        f\"{base_dir}/Results/Leech results/{type}/results_data_{type}.xlsx\",\n",
    "                        index=True,\n",
    "                    )\n",
    "                    index = index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Influence of N patches in block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:20:10.814316Z",
     "start_time": "2025-01-10T13:32:20.706388Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 384/384 [1:47:50<00:00, 16.85s/it, BRISQUE=None, Clip_IQA=0.521, Computation_Time=1.74e+9, Index=383, LPIPs_score=0.00624, SNR=40.9, TV_loss=0.000519, y=22]\n"
     ]
    }
   ],
   "source": [
    "max_3d_size_hts=[16,32]\n",
    "max_3d_size_wieners=[16,32]\n",
    "process_bm3d(type=\"Block_Size\", max_3d_size_hts=max_3d_size_hts, max_3d_size_wieners=max_3d_size_wieners)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Influence of Patch size hard and Patch size wien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T21:04:52.610950Z",
     "start_time": "2025-01-10T15:20:10.846003Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 384/384 [5:44:41<00:00, 53.86s/it, BRISQUE=None, Clip_IQA=0.521, Computation_Time=1.74e+9, Index=383, LPIPs_score=0.00624, SNR=35.6, TV_loss=0.000191, y=22]\n"
     ]
    }
   ],
   "source": [
    "bs_wieners = [8,16]\n",
    "bs_hts = [8,16]\n",
    "process_bm3d(type=\"Patch_Size\", bs_hts=bs_hts, bs_wieners=bs_wieners)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Influence of Skip steps 1 (Reference Patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T13:23:23.995486Z",
     "start_time": "2025-01-16T10:50:05.878236Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 96/96 [2:33:18<00:00, 95.81s/it, BRISQUE=None, Clip_IQA=0.521, Computation_Time=1.74e+9, Index=95, LPIPs_score=0.00624, SNR=40.7, TV_loss=0.000499, y=22] \n"
     ]
    }
   ],
   "source": [
    "step_hts = [1]\n",
    "step_wieners = [1]\n",
    "process_bm3d(type=\"Step_size\", step_hts=step_hts, step_wieners=step_wieners)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Influence of Thresholds (Hard and Wiener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T19:09:41.179770Z",
     "start_time": "2025-01-14T14:42:29.737716Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 864/864 [4:27:11<00:00, 18.55s/it, BRISQUE=None, Clip_IQA=0.521, Computation_Time=1.74e+9, Index=863, LPIPs_score=0.00624, SNR=40.8, TV_loss=0.000495, y=22]\n"
     ]
    }
   ],
   "source": [
    "tau_matches= [1500,3000,4500]\n",
    "tau_match_wieners= [200,400,600]\n",
    "process_bm3d(type=\"Threshold_Hard_Wiener\", tau_matchs=tau_matches, tau_match_wieners=tau_match_wieners)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Influence of others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T20:52:56.920761Z",
     "start_time": "2025-01-15T12:12:14.622925Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 1728/1728 [8:40:42<00:00, 18.08s/it, BRISQUE=None, Clip_IQA=0.521, Computation_Time=1.74e+9, Index=1727, LPIPs_score=0.00624, SNR=40, TV_loss=0.000423, y=22]   \n"
     ]
    }
   ],
   "source": [
    "lambda_thr3ds=[2.0,2.7,3.3]\n",
    "gammas=[2.0,4.0]\n",
    "beta_wieners=[1.0,2.0,3.0]\n",
    "process_bm3d(type=\"others\", lambda_thr3ds=lambda_thr3ds, gammas=gammas, beta_wieners = beta_wieners)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Influence of Skip steps 5 (Reference Patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T19:47:42.856847Z",
     "start_time": "2025-01-17T19:29:50.237981Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 96/96 [17:52<00:00, 11.17s/it, BRISQUE=None, Clip_IQA=0.521, Computation_Time=1.74e+9, Index=95, LPIPs_score=0.00624, SNR=39.8, TV_loss=0.00053, y=22] \n"
     ]
    }
   ],
   "source": [
    "step_hts = [5]\n",
    "step_wieners = [5]\n",
    "process_bm3d(type=\"Step_size_5\", step_hts=step_hts, step_wieners=step_wieners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T12:00:56.092383Z",
     "start_time": "2025-01-19T12:00:56.065455Z"
    }
   },
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "def process_bm3d(\n",
    "    type,\n",
    "    transform_2d_ht_names=[\"dct\", \"bior1.5\"],\n",
    "    max_3d_size_hts=[32],\n",
    "    max_3d_size_wieners=[32],\n",
    "    bs_wieners=[8],\n",
    "    step_wieners=[3],\n",
    "    bs_hts=[8],\n",
    "    nfs=[32],\n",
    "    search_window_hts=[39],\n",
    "    search_window_wieners=[39],\n",
    "    step_hts=[3],\n",
    "    tau_matchs=[3000],\n",
    "    tau_match_wieners=[400],\n",
    "    lambda_thr3ds=[2.7],\n",
    "    gammas=[2.0],\n",
    "    beta_wieners=[2.0]\n",
    "):\n",
    "\n",
    "    # Storage for results\n",
    "    results_data = []\n",
    "    index = 0\n",
    "    y_s = [15, 16, 17, 18, 19, 20, 21, 22]\n",
    "\n",
    "    # Combine parameters for grid search\n",
    "    parameter_combinations = itertools.product(\n",
    "        y_s,\n",
    "        transform_2d_ht_names,\n",
    "        max_3d_size_hts,\n",
    "        max_3d_size_wieners,\n",
    "        bs_wieners,\n",
    "        step_wieners,\n",
    "        bs_hts,\n",
    "        nfs,\n",
    "        search_window_hts,\n",
    "        search_window_wieners,\n",
    "        step_hts,\n",
    "        tau_matchs,\n",
    "        tau_match_wieners,\n",
    "        lambda_thr3ds,\n",
    "        gammas,\n",
    "        beta_wieners,\n",
    "    )\n",
    "\n",
    "    parameter_combinations = list(parameter_combinations)\n",
    "    total_combinations = len(parameter_combinations)\n",
    "\n",
    "    sigma_psd_values = [*range(5, 31, 5)]\n",
    "    stage_args = [BM3DStages.ALL_STAGES]\n",
    "    total_iterations = len(parameter_combinations) * len(stage_args) * len(sigma_psd_values)\n",
    "\n",
    "\n",
    "    with tqdm(range(total_iterations), desc=\"Progress\") as pbar:\n",
    "\n",
    "        # Iterate through all combinations\n",
    "        for i, params in enumerate(parameter_combinations):\n",
    "            (\n",
    "                y,\n",
    "                transform_2d_ht_name,\n",
    "                max_3d_size_ht,\n",
    "                max_3d_size_wiener,\n",
    "                bs_wiener,\n",
    "                step_wiener,\n",
    "                bs_ht,\n",
    "                nf,\n",
    "                search_window_ht,\n",
    "                search_window_wiener,\n",
    "                step_ht,\n",
    "                tau_match,\n",
    "                tau_match_wiener,\n",
    "                lambda_thr3d,\n",
    "                gamma,\n",
    "                beta_wiener,\n",
    "            ) = params\n",
    "\n",
    "            # Configure BM3D profile\n",
    "            profile = profiles.BM3DProfile()\n",
    "            # Transforms used\n",
    "            profile.transform_2d_ht_name = transform_2d_ht_name  # 'bior1.5'\n",
    "            profile.transform_2d_wiener_name = \"dct\"\n",
    "\n",
    "            # -- Exact variances for correlated noise: --\n",
    "\n",
    "            # Variance calculation parameters\n",
    "            profile.nf = nf  # 32  # domain size for FFT computations\n",
    "            profile.k = 4  # how many layers of var3D to calculate\n",
    "\n",
    "            # Block matching\n",
    "            profile.gamma = gamma  # 3.0  # Block matching correction factor\n",
    "\n",
    "            # -- Classic BM3D for correlated noise --\n",
    "\n",
    "            # Hard-thresholding (HT) parameters:\n",
    "            profile.bs_ht = bs_ht  # 8  # N1 x N1 is the block size used for the hard-thresholding (HT) filtering\n",
    "            profile.step_ht = (\n",
    "                step_ht  # 3# sliding step to process every next reference block\n",
    "            )\n",
    "            profile.max_3d_size_ht = max_3d_size_ht  # 16  # maximum number of similar blocks (maximum size of the 3rd dimension of a 3D array)\n",
    "            profile.search_window_ht = search_window_ht  # 39  # side length of the search neighborhood for full-search block-matching (BM), must be odd\n",
    "            profile.tau_match = (\n",
    "                tau_match  # 3000  # threshold for the block-distance (d-distance)\n",
    "            )\n",
    "\n",
    "            # None in these parameters results in automatic parameter selection for them\n",
    "            profile.lambda_thr3d = lambda_thr3d  # None  # 2.7  # threshold parameter for the hard-thresholding in 3D transform domain\n",
    "            profile.mu2 = lambda_thr3d  # None  # 1.0\n",
    "\n",
    "            # Wiener filtering parameters:\n",
    "            profile.bs_wiener = bs_wiener  # 8\n",
    "            profile.step_wiener = step_wiener  # 3\n",
    "            profile.max_3d_size_wiener = max_3d_size_wiener  # 32\n",
    "            profile.search_window_wiener = search_window_wiener  # 39\n",
    "            profile.tau_match_wiener = tau_match_wiener  # 400\n",
    "            profile.beta_wiener = beta_wiener  # 2.0\n",
    "            profile.dec_level = (\n",
    "                0  # dec. levels of the dyadic wavelet 2D transform for blocks\n",
    "            )\n",
    "\n",
    "            output_base_folder = f\"{base_dir}/Results/resTarget results/{type}/\"\n",
    "            os.makedirs(output_base_folder, exist_ok=True)\n",
    "\n",
    "            file_path = f\"{base_dir}/Dataset/resTarget/2024_02_09_10_17_52_img_x_15_y_{y}_r_0_g_1_b_0_cropped.exr\"\n",
    "\n",
    "            # Load and preprocess noisy image\n",
    "            noisy_img = process_exr(file_path)  # 800x800\n",
    "            noisy_img = (noisy_img * 255).astype(\"uint8\")\n",
    "\n",
    "            # Process each stage and sigma_psd value\n",
    "            for stage_arg in stage_args:\n",
    "                for sigma_psd in sigma_psd_values:\n",
    "                    # start timer\n",
    "                    start_time = time.time()\n",
    "\n",
    "                    denoised_img = bm3d(\n",
    "                        noisy_img, sigma_psd=sigma_psd, stage_arg=stage_arg, profile=profile\n",
    "                    )\n",
    "\n",
    "                    end_time = time.time()\n",
    "\n",
    "                    snr_max_min_db, snr_mean_db = calculate_snr(denoised_img)\n",
    "                    img_tensor = numpy_to_torch(denoised_img)\n",
    "\n",
    "                    # BRISQUELoss\n",
    "                    try:\n",
    "                        loss = BRISQUELoss(reduction=\"sum\").to(device)\n",
    "                        brsique_score = loss(img_tensor)\n",
    "                        brsique_score.backward()\n",
    "                        brsique_score = brsique_score.item()\n",
    "                    except:\n",
    "                        brsique_score = None\n",
    "\n",
    "                    # TV\n",
    "                    loss = TVLoss().to(device)\n",
    "                    tv = loss(img_tensor)\n",
    "                    tv.backward()\n",
    "                    tv = tv.item()\n",
    "\n",
    "                    # CLIP IQA\n",
    "                    try:\n",
    "                        clipiqa = CLIPIQA().to(device)\n",
    "                        clipiqa_score = clipiqa(img_tensor).item()#\n",
    "                    except:\n",
    "                        clipiqa_score = None\n",
    "\n",
    "\n",
    "                    # LPIPS\n",
    "                    try:\n",
    "                        noisy_img_torch = numpy_to_torch(noisy_img)\n",
    "                        loss_fn = load_lpips_model()\n",
    "                        lpips_score = loss_fn(noisy_img_torch, img_tensor).item()\n",
    "                    except:\n",
    "                        lpips_score = None\n",
    "\n",
    "                    denoised_img_float32 = (\n",
    "                        denoised_img.astype(\"float32\") / 255.0\n",
    "                    )  # Normalize to [0, 1] range\n",
    "                    # OpenEXR requires the data to be split into channels (R, G, B)\n",
    "                    R = denoised_img_float32[:, :, 0].tobytes()  # Red channel\n",
    "                    G = denoised_img_float32[:, :, 1].tobytes()  # Green channel\n",
    "                    B = denoised_img_float32[:, :, 2].tobytes()  # Blue channel\n",
    "\n",
    "                    # Define EXR header\n",
    "                    header = OpenEXR.Header(\n",
    "                        denoised_img_float32.shape[1], denoised_img_float32.shape[0]\n",
    "                    )  # Width, Height\n",
    "\n",
    "                    # Write the data to an EXR file\n",
    "                    path_final = output_base_folder + f\"{type}-{index}_image_res.exr\"\n",
    "                    exr_file = OpenEXR.OutputFile(path_final, header)\n",
    "                    exr_file.writePixels({\"R\": R, \"G\": G, \"B\": B})\n",
    "                    exr_file.close()\n",
    "\n",
    "                    # Store all parameter values and results\n",
    "                    results_data.append(\n",
    "                        {\n",
    "                            \"Coordinate y\": y,\n",
    "                            \"Sigma PSD\": sigma_psd,\n",
    "                            \"Stage_arg\": stage_arg,\n",
    "                            \"Transform 2D\": transform_2d_ht_name,\n",
    "                            \"Max 3D Size HT\": max_3d_size_ht,\n",
    "                            \"Max 3D Size Wiener\": max_3d_size_wiener,\n",
    "                            \"Block Size Wiener\": bs_wiener,\n",
    "                            \"Step Wiener\": step_wiener,\n",
    "                            \"Block Size HT\": bs_ht,\n",
    "                            \"Step HT\": step_ht,\n",
    "                            \"Number of Features (NF)\": nf,\n",
    "                            \"Search Window HT\": search_window_ht,\n",
    "                            \"Search Window Wiener\": search_window_wiener,\n",
    "                            \"Tau Match\": tau_match,\n",
    "                            \"Tau Match Wiener\": tau_match_wiener,\n",
    "                            \"Lambda Thr3D\": lambda_thr3d,\n",
    "                            \"Gamma\": gamma,\n",
    "                            \"Beta Wiener\": beta_wiener,\n",
    "                            \"SNR Max-Min (dB)\": snr_max_min_db,\n",
    "                            \"SNR Mean (dB)\": snr_mean_db,\n",
    "                            \"BRISQUE\": brsique_score,\n",
    "                            \"Total Variation\": tv,\n",
    "                            \"Clip-IQA\": clipiqa_score,\n",
    "                            \"LPIPs_score\" : lpips_score,\n",
    "                            \"Computation Time\" : end_time,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "                    # Convert to a DataFrame\n",
    "                    pbar.set_postfix(Index = index, y = y, SNR = snr_max_min_db, BRISQUE = brsique_score, TV_loss = tv, Clip_IQA = clipiqa_score, LPIPs_score = lpips_score, Computation_Time = end_time)\n",
    "                    pbar.update(1)\n",
    "\n",
    "                    df = pd.DataFrame(results_data)\n",
    "                    # Save to Excel\n",
    "                    df.to_excel(\n",
    "                        f\"{base_dir}/Results/resTarget results/{type}/results_data_{type}.xlsx\",\n",
    "                        index=True,\n",
    "                    )\n",
    "                    index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T20:29:41.722325Z",
     "start_time": "2025-01-17T20:03:43.593671Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 384/384 [25:58<00:00,  4.06s/it, BRISQUE=96.1, Clip_IQA=0.325, Computation_Time=1.74e+9, Index=383, LPIPs_score=0.0493, SNR=12.7, TV_loss=0.0352, y=22]\n"
     ]
    }
   ],
   "source": [
    "max_3d_size_hts=[16,32]\n",
    "max_3d_size_wieners=[16,32]\n",
    "process_bm3d(type=\"Block_Size\", max_3d_size_hts=max_3d_size_hts, max_3d_size_wieners=max_3d_size_wieners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T17:55:46.183372Z",
     "start_time": "2025-01-18T17:05:17.447291Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 384/384 [50:28<00:00,  7.89s/it, BRISQUE=110, Clip_IQA=0.337, Computation_Time=1.74e+9, Index=383, LPIPs_score=0.0494, SNR=12.3, TV_loss=0.0265, y=22] \n"
     ]
    }
   ],
   "source": [
    "bs_wieners = [8,16]\n",
    "bs_hts = [8,16]\n",
    "process_bm3d(type=\"Patch_Size\", bs_hts=bs_hts, bs_wieners=bs_wieners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T18:42:39.060086Z",
     "start_time": "2025-01-18T18:30:46.309959Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 96/96 [11:52<00:00,  7.42s/it, BRISQUE=96.4, Clip_IQA=0.325, Computation_Time=1.74e+9, Index=95, LPIPs_score=0.0492, SNR=12.7, TV_loss=0.0344, y=22]\n"
     ]
    }
   ],
   "source": [
    "step_hts = [1]\n",
    "step_wieners = [1]\n",
    "process_bm3d(type=\"Step_size\", step_hts=step_hts, step_wieners=step_wieners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T18:30:26.019593Z",
     "start_time": "2025-01-18T18:24:27.397553Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 96/96 [05:58<00:00,  3.74s/it, BRISQUE=101, Clip_IQA=0.325, Computation_Time=1.74e+9, Index=95, LPIPs_score=0.0492, SNR=12.8, TV_loss=0.0377, y=22] \n"
     ]
    }
   ],
   "source": [
    "step_hts = [5]\n",
    "step_wieners = [5]\n",
    "process_bm3d(type=\"Step_size_5\", step_hts=step_hts, step_wieners=step_wieners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T19:45:19.279076Z",
     "start_time": "2025-01-18T18:42:44.188515Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 864/864 [1:02:35<00:00,  4.35s/it, BRISQUE=96.3, Clip_IQA=0.325, Computation_Time=1.74e+9, Index=863, LPIPs_score=0.0493, SNR=12.7, TV_loss=0.0352, y=22]\n"
     ]
    }
   ],
   "source": [
    "tau_matches= [1500,3000,4500]\n",
    "tau_match_wieners= [200,400,600]\n",
    "process_bm3d(type=\"Threshold_Hard_Wiener\", tau_matchs=tau_matches, tau_match_wieners=tau_match_wieners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T13:42:48.206075Z",
     "start_time": "2025-01-19T12:01:06.188296Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 1728/1728 [1:41:42<00:00,  3.53s/it, BRISQUE=112, Clip_IQA=0.325, Computation_Time=1.74e+9, Index=1727, LPIPs_score=None, SNR=12.8, TV_loss=0.0324, y=22] \n"
     ]
    }
   ],
   "source": [
    "lambda_thr3ds=[2.0,2.7,3.3]\n",
    "gammas=[2.0,4.0]\n",
    "beta_wieners=[1.0,2.0,3.0]\n",
    "process_bm3d(type=\"others\", lambda_thr3ds=lambda_thr3ds, gammas=gammas, beta_wieners = beta_wieners)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
